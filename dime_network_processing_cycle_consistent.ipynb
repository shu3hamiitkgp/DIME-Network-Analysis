{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import os \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "# from thefuzz import fuzz, process\n",
    "import powerlaw\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# !pip install mpmath \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "def plot_degree(degree, number_of_bins=50, log_binning=True, base=2):\n",
    "    \"\"\"\n",
    "    Given a degree sequence, return the y values (probability) and the\n",
    "    x values (support) of a degree distribution that you're going to plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    degree (np.ndarray or list):\n",
    "        a vector of length N that corresponds to the degree, k_i, of every\n",
    "        node, v_i, in the network\n",
    "\n",
    "    number_of_bins (int):\n",
    "        length of output vectors\n",
    "    \n",
    "    log_binning (bool)\n",
    "        if you are plotting on a log-log axis, then this is useful\n",
    "    \n",
    "    base (int):\n",
    "        log base, defaults to 2\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x, y (np.ndarray):\n",
    "        the support and probability values of the degree distribution\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # We need to define the support of our distribution\n",
    "    lower_bound = min(degree)\n",
    "    upper_bound = max(degree)\n",
    "    \n",
    "    # And the bins\n",
    "    if log_binning:\n",
    "        log = np.log2 if base == 2 else np.log10\n",
    "        lower_bound = log(lower_bound) if lower_bound >= 1 else 0.0\n",
    "        upper_bound = log(upper_bound)\n",
    "        bins = np.logspace(lower_bound,upper_bound,number_of_bins, base = base)\n",
    "    else:\n",
    "        bins = np.linspace(lower_bound,upper_bound,number_of_bins)\n",
    "    \n",
    "    # Then we can compute the histogram using numpy\n",
    "    y, __ = np.histogram(degree, \n",
    "                         bins=bins,\n",
    "                         density=True)\n",
    "    # Now, we need to compute for each y the value of x\n",
    "    x = bins[1:] - np.diff(bins)/2.0\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sql loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### CID FROM CSV    (~10 secs)\n",
    "# unique_cid_all = contributor_data['bonica.cid'].unique()\n",
    "# # print(unique_cid_all)\n",
    "# unique_cid_all = unique_cid_all[~np.isnan(unique_cid_all)]\n",
    "# # print(unique_cid_all)\n",
    "\n",
    "### CID FROM sql    (~40 secs)\n",
    "sqliteConnection = sqlite3.connect('dime_v3.sqlite3')\n",
    "cursor = sqliteConnection.cursor()\n",
    "unique_cid_all_sql = cursor.execute(\"SELECT DISTINCT bonica_cid FROM donorDB\").fetchall()\n",
    "unique_cid_all_sql = [x[0] for x in unique_cid_all_sql]\n",
    "sql_cid_series = pd.Series(unique_cid_all_sql)\n",
    "sql_cid_series = sql_cid_series[~pd.isnull(sql_cid_series)]\n",
    "unique_cid_all_sql_array = sql_cid_series.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RID from entire contrib db\n",
    "unique_rid_all_cycle = cursor.execute(\"SELECT DISTINCT bonica_rid FROM contribDB WHERE cycle='2008' OR cycle='2012'\").fetchall()\n",
    "\n",
    "# ~ >20 min run time for entire contrib DB\n",
    "# ~ 8 min run time for only 2008, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rid_all_cycle = [x[0] for x in unique_rid_all_cycle]\n",
    "sql_rid_all_cycle_series = pd.Series(unique_rid_all_cycle)\n",
    "sql_rid_all_cycle_series = sql_rid_all_cycle_series[~pd.isnull(sql_rid_all_cycle_series)]\n",
    "unique_rid_all_cycle_array = sql_rid_all_cycle_series.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95520\n",
      "95520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_31268\\2542202054.py:7: DtypeWarning: Columns (12,15,16,17,40,42,43,44,46,48,49,53,54,57,59,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193488\n",
      "25968\n",
      "123936\n"
     ]
    }
   ],
   "source": [
    "### CHECK RID\n",
    "print(len(unique_rid_all_cycle))\n",
    "print(len(unique_rid_all_cycle_array))\n",
    "# unique_cid_all_cycle\n",
    "unique_rid_all_cycle_array\n",
    "\n",
    "recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\")\n",
    "unique_rid_all = recipient_data['bonica.rid'].unique()\n",
    "\n",
    "print(len(unique_rid_all))\n",
    "unique_rid_all\n",
    "# print(len(unique_rid_all_sql))\n",
    "# print(len(unique_rid_all_sql_array))\n",
    "# unique_rid_all_sql_array\n",
    "\n",
    "# if (all((unique_rid_all_sql_array) == (unique_rid_all_cycle_array))): print('yay')\n",
    "# else: print('aww')\n",
    "\n",
    "set(unique_rid_all_cycle_array) - set(unique_rid_all)\n",
    "# set(unique_rid_all_cycle_array) - set(unique_rid_all_sql_array)\n",
    "\n",
    "print(len(set(unique_rid_all_cycle_array) - set(unique_rid_all)))\n",
    "print(len(set(unique_rid_all) - set(unique_rid_all_cycle_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from entire contrib db\n",
    "unique_cid_all_cycle = cursor.execute(\"SELECT DISTINCT bonica_cid FROM contribDB\").fetchall()\n",
    "unique_cid_all_cycle = [x[0] for x in unique_cid_all_cycle]\n",
    "sql_cid_all_cycle_series = pd.Series(unique_cid_all_cycle)\n",
    "sql_cid_all_cycle_series = sql_cid_all_cycle_series[~pd.isnull(sql_cid_all_cycle_series)]\n",
    "unique_cid_all_cycle_array = sql_cid_all_cycle_series.to_numpy()\n",
    "# ~ 3.5 min run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47833160\n",
      "47833160\n",
      "36270758\n",
      "36270757\n",
      "11562407\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### CHECK CID\n",
    "print(len(unique_cid_all_cycle))\n",
    "print(len(unique_cid_all_cycle_array))\n",
    "# unique_cid_all_cycle\n",
    "# unique_cid_all_cycle_array\n",
    "\n",
    "print(len(unique_cid_all_sql))\n",
    "print(len(unique_cid_all_sql_array))\n",
    "# unique_cid_all_sql_array\n",
    "\n",
    "# if (all((unique_cid_all_sql_array) == (unique_cid_all_cycle_array))): print('yay')\n",
    "# else: print('aww')\n",
    "\n",
    "print(len(set(unique_cid_all_cycle_array) - set(unique_cid_all_sql_array)))\n",
    "print(len(set(unique_cid_all_sql_array) - set(unique_cid_all_cycle_array)))\n",
    "# ~ 30 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load year database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_31268\\1755285770.py:8: DtypeWarning: Columns (14,19,21,22,25,27,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  contrib_12 = pd.read_csv(contrib_file_to_read, usecols=columns_to_read_csv, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "## CYCLE TO READ\n",
    "del contrib_80\n",
    "cycle = '2012'\n",
    "# columns_to_read_sql = ['amount', 'bonica_cid', 'contributor_name', 'contributor_type', 'contributor_gender',  'contributor_state', 'contributor_occupation',  'occ_standardized', 'is_corp', 'recipient_name', 'bonica_rid', 'recipient_party', 'recipient_type', 'recipient_state', 'seat', 'contributor_cfscore', 'candidate_cfscore', 'bk_ref_transaction_id']\n",
    "columns_to_read_csv = ['cycle', 'date', 'transaction.id', 'amount', 'bonica.cid', 'contributor.name', 'contributor.type', 'contributor.gender',  'contributor.state', 'contributor.occupation',  'occ.standardized', 'is.corp', 'recipient.name', 'bonica.rid', 'recipient.party', 'recipient.type', 'recipient.state', 'seat', 'contributor.cfscore', 'candidate.cfscore', 'bk.ref.transaction.id']\n",
    "contrib_file_to_read = \"contribDB_\" + cycle + \".csv\"\n",
    "\n",
    "contrib_12 = pd.read_csv(contrib_file_to_read, usecols=columns_to_read_csv, encoding=\"latin1\")\n",
    "# contrib_00 = pd.read_csv(contrib_file_to_read, usecols=columns_to_read_csv, encoding=\"latin1\")\n",
    "\n",
    "# run time for 2000: ~25 secs\n",
    "# run time for 2008: ~2 mins\n",
    "# run time for 2012: ~3 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node Id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_31268\\2474569195.py:2: DtypeWarning: Columns (12,15,16,17,40,42,43,44,46,48,49,53,54,57,59,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\")\n"
     ]
    }
   ],
   "source": [
    "### RID FROM CSV    (~1 secs)\n",
    "recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\")\n",
    "unique_rid_all = recipient_data['bonica.rid'].unique()\n",
    "rid_to_cid_dict = recipient_data[recipient_data['bonica.cid'] >= 0].groupby('bonica.rid')['bonica.cid'].agg(lambda x: list(set(x))).to_dict()\n",
    "# ~7 secs\n",
    "\n",
    "# contributor_data = pd.read_csv(\"dime_contributors_1979_2020.csv\", encoding=\"latin1\")\n",
    "# approx 7 min load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TESTING\n",
    "# set(unique_rid_all)\n",
    "# type(sorted(set(unique_rid_all)))\n",
    "# type(sorted(unique_rid_all))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_31268\\2379254060.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  contrib_for_net.loc[:, ('source_id')] = contrib_for_net['bonica.cid'].map(b_cid_to_nid) #.fillna('')\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_31268\\2379254060.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  contrib_for_net.loc[:, ('sink_id')] = contrib_for_net['bonica.rid'].map(b_rid_to_nid) #.fillna('')\n"
     ]
    }
   ],
   "source": [
    "contrib_df = contrib_12\n",
    "contrib_df_house_comm = contrib_df[contrib_df['seat'].isin(['federal:committee', 'federal:527', 'federal:president', 'federal:senate'])]\n",
    "contrib_for_net = contrib_df_house_comm\n",
    "\n",
    "# unique_rid = contrib_for_net['bonica.rid'].unique()\n",
    "# unique_cid = contrib_for_net['bonica.cid'].unique()\n",
    "\n",
    "unique_rid = unique_rid_all_cycle_array\n",
    "unique_cid = unique_cid_all_cycle_array\n",
    "\n",
    "# unique_rid = unique_rid_all\n",
    "# unique_cid = unique_cid_all_sql_array\n",
    "\n",
    "n_rid = len(unique_rid)\n",
    "n_cid = len(unique_cid)\n",
    "\n",
    "b_rid_to_nid = dict(zip(unique_rid, range(1, n_rid+1)))\n",
    "\n",
    "b_cid_to_nid = dict(zip(unique_cid, range(n_rid+1, n_rid+n_cid+1)))\n",
    "\n",
    "count_replace = 0\n",
    "for key in b_rid_to_nid:\n",
    "    if rid_to_cid_dict.get(key, False):\n",
    "        for cid in rid_to_cid_dict[key]:\n",
    "            if cid in b_cid_to_nid:\n",
    "                count_replace += 1\n",
    "                # print(b_cid_to_nid.get(cid, 'Nan'))\n",
    "                # print(str(key) + ' - ' + str(b_rid_to_nid[key]) + ' : ' + str(b_cid_to_nid.get(cid, 'Nan')) + ' - ' + str(cid))\n",
    "                b_cid_to_nid[cid] = b_rid_to_nid[key]\n",
    "                # print(str(key) + ' - ' + str(b_rid_to_nid[key]) + ' : ' + str(b_cid_to_nid[cid]) + ' - ' + str(cid))\n",
    "                # print(str(key) + ' : ' + str(cid))\n",
    "print(count_replace)\n",
    "# run time: ~7 secs\n",
    "\n",
    "## apply Node IDs\n",
    "\n",
    "# print(contrib_for_net.shape)\n",
    "contrib_for_net.loc[:, ('source_id')] = contrib_for_net['bonica.cid'].map(b_cid_to_nid) #.fillna('')\n",
    "# print(contrib_for_net.shape)\n",
    "contrib_for_net.loc[:, ('sink_id')] = contrib_for_net['bonica.rid'].map(b_rid_to_nid) #.fillna('')\n",
    "# print(contrib_for_net.shape)\n",
    "# display(contrib_for_net)\n",
    "# ~20 secs\n",
    "\n",
    "aggregated_amounts = contrib_for_net.groupby(['source_id', 'sink_id']).agg({'amount': 'sum', \n",
    "                                                                            'cycle': 'first', 'date': 'first', 'transaction.id': 'first', 'bonica.cid': 'first', 'contributor.name': 'first', 'contributor.type': 'first',\n",
    "                                                                            'contributor.gender': 'first', 'contributor.state': 'first', 'contributor.occupation': 'first', 'occ.standardized': 'first', 'is.corp': 'first',\n",
    "                                                                            'recipient.name': 'first', 'bonica.rid': 'first', 'recipient.party': 'first', 'recipient.type': 'first', 'recipient.state': 'first',\n",
    "                                                                            'seat': 'first', 'contributor.cfscore': 'first', 'candidate.cfscore': 'first', 'bk.ref.transaction.id': 'first'}).reset_index()\n",
    "\n",
    "summed_contribs_for_net = aggregated_amounts\n",
    "# display(aggregated_amounts)\n",
    "# ~ 1 mins 2008\n",
    "# ~ 2.5 mins 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples of data for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id                                           10\n",
       "sink_id                                          17783\n",
       "amount                                      250.000000\n",
       "cycle                                             2012\n",
       "date                                        2011-09-14\n",
       "transaction.id                     e:ind:2012:40176719\n",
       "bonica.cid                           5271641725.000000\n",
       "contributor.name                          elgar, steve\n",
       "contributor.type                                     I\n",
       "contributor.gender                                   M\n",
       "contributor.state                                   ID\n",
       "contributor.occupation                       scientist\n",
       "occ.standardized                                  None\n",
       "is.corp                                           None\n",
       "recipient.name            IDAHO STATE DEMOCRATIC PARTY\n",
       "bonica.rid                                    comm7197\n",
       "recipient.party                                    100\n",
       "recipient.type                                    COMM\n",
       "recipient.state                                     ID\n",
       "seat                                 federal:committee\n",
       "contributor.cfscore                          -0.890000\n",
       "candidate.cfscore                            -1.080000\n",
       "bk.ref.transaction.id                             None\n",
       "Name: 13, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>sink_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>cycle</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction.id</th>\n",
       "      <th>bonica.cid</th>\n",
       "      <th>contributor.name</th>\n",
       "      <th>contributor.type</th>\n",
       "      <th>contributor.gender</th>\n",
       "      <th>contributor.state</th>\n",
       "      <th>contributor.occupation</th>\n",
       "      <th>occ.standardized</th>\n",
       "      <th>is.corp</th>\n",
       "      <th>recipient.name</th>\n",
       "      <th>bonica.rid</th>\n",
       "      <th>recipient.party</th>\n",
       "      <th>recipient.type</th>\n",
       "      <th>recipient.state</th>\n",
       "      <th>seat</th>\n",
       "      <th>contributor.cfscore</th>\n",
       "      <th>candidate.cfscore</th>\n",
       "      <th>bk.ref.transaction.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_id, sink_id, amount, cycle, date, transaction.id, bonica.cid, contributor.name, contributor.type, contributor.gender, contributor.state, contributor.occupation, occ.standardized, is.corp, recipient.name, bonica.rid, recipient.party, recipient.type, recipient.state, seat, contributor.cfscore, candidate.cfscore, bk.ref.transaction.id]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "display(summed_contribs_for_net.iloc[13])\n",
    "summed_contribs_for_net[summed_contribs_for_net['sink_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(summed_contribs_for_net.shape)\n",
    "\n",
    "# display(contrib_df_house_comm[contrib_df_house_comm['name'] == 3545311])\n",
    "\n",
    "display(contrib_df_house_comm.iloc[13, :])\n",
    "\n",
    "display(contrib_df_house_comm.head(25))\n",
    "# rid_to_cid_dict = \n",
    "contrib_df_house_comm.iloc[13]\n",
    "contrib_for_net[contrib_for_net['sink_id'].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing data processing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrib_df = contrib_12\n",
    "# del contrib_08\n",
    "\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(contrib_df)\n",
    "# display(contrib_df.iloc[:,[14]])\n",
    "# counts = pd.DataFrame(contrib_df['transaction.id'].value_counts())\n",
    "# print(counts[counts.iloc[:,0] <= 1])\n",
    "\n",
    "# contrib_df['transaction.id' == '105694355']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "# display(contrib_df)\n",
    "\n",
    "# display(contrib_80_fed[(contrib_80_fed['seat'] == 'federal:president') & (contrib_80_fed['recipient_type'] == 'comm')])\n",
    "filtered_db = contrib_df[(~contrib_df['bk.ref.transaction.id'].isna())]\n",
    "\n",
    "print(contrib_df['bk.ref.transaction.id'].value_counts())\n",
    "# print(filtered_db['contributor_type'].value_counts())\n",
    "display(filtered_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# display(contrib_for_net)\n",
    "# # display(contrib_for_net.drop('amount',axis = 1))\n",
    "\n",
    "# summed_amounts = contrib_for_net.groupby(['source_id', 'sink_id'], as_index=False)['amount'].sum().reset_index()\n",
    "# display(summed_amounts)\n",
    "\n",
    "# left_merged_nodrop = pd.merge(summed_amounts, contrib_for_net, how=\"left\", on=[\"source_id\", \"sink_id\"])\n",
    "# display(left_merged_nodrop)\n",
    "\n",
    "# left_merged = pd.merge(summed_amounts, contrib_for_net.drop('amount',axis = 1), how=\"left\", on=[\"source_id\", \"sink_id\"])\n",
    "# # display(left_merged)\n",
    "# summed_contribs_for_net = left_merged   #[summed_amounts['amount'] > min_link_amount]\n",
    "# display(summed_contribs_for_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_read_csv = ['cycle', 'date', 'transaction.id', 'amount', \n",
    "#                        'bonica.cid', 'contributor.name', 'contributor.type', 'contributor.gender',  'contributor.state', 'contributor.occupation',  'occ.standardized', 'is.corp', \n",
    "#                        'recipient.name', 'bonica.rid', 'recipient.party', 'recipient.type', 'recipient.state', 'seat', \n",
    "#                        'contributor.cfscore', 'candidate.cfscore', 'bk.ref.transaction.id']\n",
    "\n",
    "\n",
    "\n",
    "# agg_amounts = contrib_for_net.groupby(['source_id', 'sink_id'])['amount'].transform(\"sum\")\n",
    "# display(agg_amounts)\n",
    "\n",
    "# aggregated_amounts = contrib_for_net.groupby(['source_id', 'sink_id']).agg(total_amount=pd.NamedAgg(column=\"amount\", aggfunc=\"sum\"))\n",
    "    # b_min=pd.NamedAgg(column=\"B\", aggfunc=\"min\"),\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_read_csv = ['transaction.id', 'amount', \n",
    "#                        'bonica.cid', 'contributor.name', 'contributor.type', 'contributor.gender',  'contributor.state', 'contributor.occupation',  'occ.standardized', 'is.corp', \n",
    "#                        'recipient.name', 'bonica.rid', 'recipient.party', 'recipient.type', 'recipient.state', 'seat', \n",
    "#                        'contributor.cfscore', 'candidate.cfscore', 'bk.ref.transaction.id']\n",
    "\n",
    "# summed_contribs_for_net = aggregated_amounts\n",
    "# display(aggregated_amounts)\n",
    "\n",
    "contrib_net = nx.DiGraph()\n",
    "\n",
    "for index, row in summed_contribs_for_net.iterrows():\n",
    "# if (not contrib_net.has_node(row['source_id'])):\n",
    "    contrib_net.add_node(row['source_id'],\n",
    "                        name_contributor=row['contributor.name'],\n",
    "                        corp_ind=row['contributor.type'],\n",
    "                        gender_contributor=row['contributor.gender'],\n",
    "                        state_contributor=row['contributor.state'],\n",
    "                        occupation_standardized=row['occ.standardized'],\n",
    "                        occupation_writen=row['contributor.occupation'],\n",
    "                        partisan_contributor=row['contributor.cfscore'])\n",
    "# if (not contrib_net.has_node(row['sink_id'])):\n",
    "    contrib_net.add_node(row['sink_id'],\n",
    "                        name_recipient=row['recipient.name'],\n",
    "                        cand_comm=row['recipient.type'],\n",
    "                        party_recipient=row['recipient.party'],\n",
    "                        state_recipient=row['contributor.state'],\n",
    "                        partisan_recipient=row['candidate.cfscore'],\n",
    "                        seat=row['seat'])\n",
    "    contrib_net.add_edge(row['source_id'], row['sink_id'], weight=row['amount'])\n",
    "\n",
    "# 2000 run time: ~1 min\n",
    "# 2008 run time: ~2.5 min\n",
    "# 2012 run time: ~4.5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(contrib_net, \"2012_pres_sen_consistent_nid_v1.gml\", str)\n",
    "#2008: ~ 1 min\n",
    "#2012: ~ 2 min \n",
    "# del contrib_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del contrib_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 3054381 nodes and 5418590 edges\n",
      "Graph density:\t 0.000000581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name_contributor': 'robles, luz',\n",
       " 'corp_ind': 'I',\n",
       " 'gender_contributor': 'F',\n",
       " 'state_contributor': 'UT',\n",
       " 'occupation_standardized': 'politicos',\n",
       " 'occupation_writen': 'senator',\n",
       " 'partisan_contributor': -0.75}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(contrib_net)\n",
    "print(\"Graph density:\\t %1.9f\" % nx.density(contrib_net))\n",
    "# contrib_net.nodes(data=True)    2034 in 2008 has both in and out\n",
    "contrib_net.nodes[213] #('1123', data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unweighted degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 2417413 nodes and 3417291 edges\n",
      "Degree of node 37: 174283\n",
      "In-degree of node 37: 174281\n",
      "Out-degree of node 37: 2\n",
      "\n",
      "Network-level properties\n",
      "Average degree: 2.83\n",
      "Average in-degree: 1.414\n",
      "Average out-degree: 1.414\n",
      "Graph density:\t 0.0000006\n"
     ]
    }
   ],
   "source": [
    "print(contrib_net)\n",
    "\n",
    "# list(contrib_net.nodes(data=True))[:10]\n",
    "\n",
    "degree = contrib_net.degree()\n",
    "in_degree = contrib_net.in_degree()\n",
    "out_degree = contrib_net.out_degree()\n",
    "\n",
    "# I ususally make this a dictionary straight away\n",
    "degree = dict(degree)\n",
    "in_degree = dict(in_degree)\n",
    "out_degree = dict(out_degree)\n",
    "\n",
    "# print(degree)\n",
    "\n",
    "node = list(contrib_net.nodes())[1]\n",
    "\n",
    "print('Degree of node %s: %d' % (node, degree[node]))\n",
    "print('In-degree of node %s: %d' % (node, in_degree[node]))\n",
    "print('Out-degree of node %s: %d' % (node, out_degree[node]))\n",
    "# print(\"Node %s's political orientation: %s\" %(node, contrib_net.nodes[node]['political_orientation']))\n",
    "print()\n",
    "print(\"Network-level properties\")\n",
    "print(\"Average degree: %1.2f\" % np.mean(list(degree.values())))\n",
    "print(\"Average in-degree: %1.3f\" % np.mean(list(in_degree.values())))\n",
    "print(\"Average out-degree: %1.3f\" % np.mean(list(out_degree.values())))\n",
    "\n",
    "print(\"Graph density:\\t %1.7f\" % nx.density(contrib_net))\n",
    "# print(contrib_net.nodes(data=True))\n",
    "# print(contrib_net.edges(data=True))\n",
    "\n",
    "# nx.write_gml(contrib_net, \"2000_fed_50000amount_no_label.gml\", str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_list = list(degree.values())\n",
    "in_degree_list = list(in_degree.values())\n",
    "out_degree_list = list(out_degree.values())\n",
    "\n",
    "x_all_degree, y_all_degree = plot_degree(degree_list, number_of_bins=50, log_binning=True, base=2)\n",
    "x_in_degree, y_in_degree = plot_degree(in_degree_list, number_of_bins=50, log_binning=True, base=2)\n",
    "x_out_degree, y_out_degree = plot_degree(out_degree_list, number_of_bins=50, log_binning=True, base=2)\n",
    "\n",
    "cols = ['#008795','#629CC0','#C8C0DD','#DEA8AB','#FFC980','#E3EA7A','#76C1CA','#999999']\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,4),dpi=150)\n",
    "\n",
    "ax.loglog(x_all_degree, y_all_degree,'o', color=cols[4], label='all', alpha=0.8)\n",
    "ax.loglog(x_in_degree, y_in_degree,'.', color=cols[1], label='in', alpha=0.8)\n",
    "ax.loglog(x_out_degree, y_out_degree,'d', color=cols[2], label='out', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize=16)\n",
    "ax.set_ylabel(r\"$P(k)$\", fontsize=16)\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.grid(linewidth=1.25, color='#999999', alpha=0.2, linestyle='-')\n",
    "\n",
    "# plt.savefig('../figs/pngs/PolBlogs_inout_degreedist.png', dpi=425, bbox_inches='tight')\n",
    "# plt.savefig('../figs/pdfs/PolBlogs_inout_degreedist.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "2.584418816701878%\n",
      "Calculating best minimal value for power law fit\n",
      "2.5811192811445727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Values less than or equal to 0 in data. Throwing out 0 or negative values\n",
      "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "2.605354273535514%\n"
     ]
    }
   ],
   "source": [
    "all_degree_fit = powerlaw.Fit(degree_list)\n",
    "print(all_degree_fit.power_law.alpha)\n",
    "in_degree_fit = powerlaw.Fit(in_degree_list)\n",
    "print(in_degree_fit.power_law.alpha)\n",
    "out_degree_fit = powerlaw.Fit(out_degree_list)\n",
    "print(out_degree_fit.power_law.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 1211360 nodes and 1766094 edges\n",
      "Degree of node 1445.0: 1647214\n",
      "In-degree of node 1445.0: 1647144\n",
      "Out-degree of node 1445.0: 70\n",
      "\n",
      "Network-level properties\n",
      "Average degree: 5713.98\n",
      "Average in-degree: 2856.989\n",
      "Average out-degree: 2856.989\n",
      "Graph density:\t 0.0000012\n"
     ]
    }
   ],
   "source": [
    "print(contrib_net)\n",
    "\n",
    "# list(contrib_net.nodes(data=True))[:10]\n",
    "\n",
    "degree_weighted = contrib_net.degree(weight='weight')\n",
    "in_degree_weighted = contrib_net.in_degree(weight='weight')\n",
    "out_degree_weighted = contrib_net.out_degree(weight='weight')\n",
    "\n",
    "# I ususally make this a dictionary straight away\n",
    "degree_weighted = dict(degree_weighted)\n",
    "in_degree_weighted = dict(in_degree_weighted)\n",
    "out_degree_weighted = dict(out_degree_weighted)\n",
    "\n",
    "# print(degree)\n",
    "\n",
    "node = list(contrib_net.nodes())[1]\n",
    "\n",
    "print('Degree of node %s: %d' % (node, degree_weighted[node]))\n",
    "print('In-degree of node %s: %d' % (node, in_degree_weighted[node]))\n",
    "print('Out-degree of node %s: %d' % (node, out_degree_weighted[node]))\n",
    "# print(\"Node %s's political orientation: %s\" %(node, contrib_net.nodes[node]['political_orientation']))\n",
    "print()\n",
    "print(\"Network-level properties\")\n",
    "print(\"Average degree: %1.2f\" % np.mean(list(degree_weighted.values())))\n",
    "print(\"Average in-degree: %1.3f\" % np.mean(list(in_degree_weighted.values())))\n",
    "print(\"Average out-degree: %1.3f\" % np.mean(list(out_degree_weighted.values())))\n",
    "\n",
    "print(\"Graph density:\\t %1.7f\" % nx.density(contrib_net))\n",
    "# print(contrib_net.nodes(data=True))\n",
    "# print(contrib_net.edges(data=True))\n",
    "\n",
    "# nx.write_gml(contrib_net, \"2000_fed_50000amount_no_label.gml\", str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_list_weighted = list(degree_weighted.values())\n",
    "in_degree_list_weighted = list(in_degree_weighted.values())\n",
    "out_degree_list_weighted = list(out_degree_weighted.values())\n",
    "\n",
    "x_all_degree, y_all_degree = plot_degree(degree_list_weighted, number_of_bins=50, log_binning=True, base=2)\n",
    "x_in_degree, y_in_degree = plot_degree(in_degree_list_weighted, number_of_bins=50, log_binning=True, base=2)\n",
    "x_out_degree, y_out_degree = plot_degree(out_degree_list_weighted, number_of_bins=50, log_binning=True, base=2)\n",
    "\n",
    "cols = ['#008795','#629CC0','#C8C0DD','#DEA8AB','#FFC980','#E3EA7A','#76C1CA','#999999']\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,4),dpi=150)\n",
    "\n",
    "ax.loglog(x_all_degree, y_all_degree,'o', color=cols[4], label='all', alpha=0.8)\n",
    "ax.loglog(x_in_degree, y_in_degree,'.', color=cols[1], label='in', alpha=0.8)\n",
    "ax.loglog(x_out_degree, y_out_degree,'d', color=cols[2], label='out', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(r\"$k$\", fontsize=16)\n",
    "ax.set_ylabel(r\"$P(k)$\", fontsize=16)\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.grid(linewidth=1.25, color='#999999', alpha=0.2, linestyle='-')\n",
    "\n",
    "# plt.savefig('../figs/pngs/PolBlogs_inout_degreedist.png', dpi=425, bbox_inches='tight')\n",
    "# plt.savefig('../figs/pdfs/PolBlogs_inout_degreedist.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(degree_list)\n",
    "degree_list_weighted_int = [int(x) for x in degree_list_weighted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "2.122726885426685%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "2.463307775038481%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "1.996232220780499%\n"
     ]
    }
   ],
   "source": [
    "all_degree_fit_weighted = powerlaw.Fit([int(x) for x in degree_list_weighted])\n",
    "print(all_degree_fit_weighted.power_law.alpha)\n",
    "in_degree_fit_weighted = powerlaw.Fit([int(x) for x in in_degree_list_weighted])\n",
    "print(in_degree_fit_weighted.power_law.alpha)\n",
    "out_degree_fit_weighted = powerlaw.Fit([int(x) for x in out_degree_list_weighted])\n",
    "print(out_degree_fit_weighted.power_law.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from SHubham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_rid_and_cid_mapping(df):\n",
    "  cid_mapping = pd.DataFrame({'contributor_ids':[], 'new_id':[]})\n",
    "  rid_to_cid_dict = get_cid_to_rid_mapping()\n",
    "  recipient_ids = df['bonica.rid'].unique()\n",
    "  rid_mapping = pd.DataFrame({'recipient_ids': recipient_ids, 'new_id': range(1, len(recipient_ids) + 1)})\n",
    "  for key, value in tqdm(rid_to_cid_dict.items()):\n",
    "    for i in range(len(value)):\n",
    "        # print(key,value[i])\n",
    "        if key in rid_mapping['recipient_ids'].values:\n",
    "            # print(key,value[i])\n",
    "            cid_mapping = pd.concat([cid_mapping,pd.DataFrame({'contributor_ids':[value[i]], 'new_id':[rid_mapping[rid_mapping.recipient_ids==key]['new_id'].values[0]]})])\n",
    "\n",
    "  contributor_ids = df['bonica.cid'].unique()\n",
    "  contributor_ids = [x for x in contributor_ids if x not in cid_mapping['contributor_ids'].values]\n",
    "  cid_mapping_rem = pd.DataFrame({'contributor_ids': contributor_ids, 'new_id': range(rid_mapping.iloc[-1]['new_id']+1, rid_mapping.iloc[-1]['new_id']+1 + len(contributor_ids))})\n",
    "  cid_mapping = pd.concat([cid_mapping,cid_mapping_rem])\n",
    "  cid_mapping.reset_index(drop=True, inplace=True)\n",
    "  return cid_mapping,rid_mapping\n",
    "\n",
    "def get_cid_to_rid_mapping():\n",
    "  recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\") #pd.read_csv(\"G:\\My Drive\\network science course\\NETS Project DIME\\Data and Code\\dime_recipients_1979_2020.csv\")\n",
    "  rid_to_cid_dict = recipient_data[(recipient_data['bonica.cid'] >= 0)].groupby('bonica.rid')['bonica.cid'].agg(lambda x: list(set(x))).to_dict()\n",
    "  del recipient_data\n",
    "  gc.collect()\n",
    "  return rid_to_cid_dict\n",
    "\n",
    "\n",
    "def get_network(df):\n",
    "\n",
    "  cid_mapping,rid_mapping = get_rid_and_cid_mapping(df)\n",
    "\n",
    "  result_df = df.merge(cid_mapping, left_on='bonica.cid', right_on='contributor_ids', how='left')\n",
    "  del df\n",
    "  gc.collect()\n",
    "  result_df.rename(columns={'new_id': 'Contributor_ID'}, inplace=True)\n",
    "  result_df = result_df.merge(rid_mapping, left_on='bonica.rid', right_on='recipient_ids', how='left')\n",
    "  result_df.rename(columns={'new_id': 'Recipient_ID'}, inplace=True)\n",
    "  # result_df.drop(['contributor_ids', 'recipient_ids'], axis=1, inplace=True)\n",
    "  result_df = result_df[['Contributor_ID','contributor_ids','contributor.name','Recipient_ID','recipient.name','contributor.type','recipient.type','contributor.cfscore','candidate.cfscore','amount']]\n",
    "  result_df = result_df.groupby(['Contributor_ID','Recipient_ID']).agg({'amount':'sum','contributor.name':'first','recipient.name':'first','recipient.type':'first','contributor.type':'first', 'contributor_ids':'first'}).reset_index()  #,'contributor.cfscore','candidate.cfscore'\n",
    "  print(result_df['Contributor_ID'].unique().shape, result_df['Recipient_ID'].unique().shape)\n",
    "  return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26568\\100941436.py:24: DtypeWarning: Columns (12,15,16,17,40,42,43,44,46,48,49,53,54,57,59,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\") #pd.read_csv(\"G:\\My Drive\\network science course\\NETS Project DIME\\Data and Code\\dime_recipients_1979_2020.csv\")\n",
      "100%|██████████| 85370/85370 [00:10<00:00, 8535.97it/s] \n"
     ]
    }
   ],
   "source": [
    "cid_mapping, rid_mapping = get_rid_and_cid_mapping(contrib_08[contrib_df['seat'].isin(['federal:committee', 'federal:527', 'federal:house'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26568\\100941436.py:24: DtypeWarning: Columns (12,15,16,17,40,42,43,44,46,48,49,53,54,57,59,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recipient_data = pd.read_csv(\"dime_recipients_1979_2020.csv\") #pd.read_csv(\"G:\\My Drive\\network science course\\NETS Project DIME\\Data and Code\\dime_recipients_1979_2020.csv\")\n",
      "100%|██████████| 85370/85370 [00:10<00:00, 8468.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1769701,) (7505,)\n"
     ]
    }
   ],
   "source": [
    "result_df_2008 = get_network(contrib_08[contrib_df['seat'].isin(['federal:committee', 'federal:527', 'federal:house'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contributor_ID</th>\n",
       "      <th>Recipient_ID</th>\n",
       "      <th>amount</th>\n",
       "      <th>contributor.name</th>\n",
       "      <th>recipient.name</th>\n",
       "      <th>recipient.type</th>\n",
       "      <th>contributor.type</th>\n",
       "      <th>contributor_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1914470</th>\n",
       "      <td>1178402.000000</td>\n",
       "      <td>2773</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>peart, dennis</td>\n",
       "      <td>CHRYSLER SERVICE CONTRACTS INC. POLITICAL SUPP...</td>\n",
       "      <td>COMM</td>\n",
       "      <td>I</td>\n",
       "      <td>3300163630.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Contributor_ID  Recipient_ID     amount contributor.name  \\\n",
       "1914470  1178402.000000          2773 225.000000    peart, dennis   \n",
       "\n",
       "                                            recipient.name recipient.type  \\\n",
       "1914470  CHRYSLER SERVICE CONTRACTS INC. POLITICAL SUPP...           COMM   \n",
       "\n",
       "        contributor.type   contributor_ids  \n",
       "1914470                I 3300163630.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_db = contrib_08[contrib_df['seat'].isin(['federal:committee', 'federal:527', 'federal:house'])]\n",
    "# display(search_db[search_db['bonica.cid'] == 3300163630])\n",
    "# print(cid_mapping[cid_mapping.contributor_ids == 3300163630])\n",
    "\n",
    "display(result_df_2008[result_df_2008.Contributor_ID == 1178402])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>sink_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>cycle</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction.id</th>\n",
       "      <th>bonica.cid</th>\n",
       "      <th>contributor.name</th>\n",
       "      <th>contributor.type</th>\n",
       "      <th>contributor.gender</th>\n",
       "      <th>...</th>\n",
       "      <th>is.corp</th>\n",
       "      <th>recipient.name</th>\n",
       "      <th>bonica.rid</th>\n",
       "      <th>recipient.party</th>\n",
       "      <th>recipient.type</th>\n",
       "      <th>recipient.state</th>\n",
       "      <th>seat</th>\n",
       "      <th>contributor.cfscore</th>\n",
       "      <th>candidate.cfscore</th>\n",
       "      <th>bk.ref.transaction.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_id, sink_id, amount, cycle, date, transaction.id, bonica.cid, contributor.name, contributor.type, contributor.gender, contributor.state, contributor.occupation, occ.standardized, is.corp, recipient.name, bonica.rid, recipient.party, recipient.type, recipient.state, seat, contributor.cfscore, candidate.cfscore, bk.ref.transaction.id]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_2008[result_df_2008.duplicated(subset=['Contributor_ID','Recipient_ID'])]\n",
    "\n",
    "summed_contribs_for_net[summed_contribs_for_net.duplicated(subset=['source_id','sink_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769701\n",
      "7505\n",
      "1769695\n",
      "7505\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df_2008.Contributor_ID.unique()))\n",
    "print(len(result_df_2008.Recipient_ID.unique()))\n",
    "print(len(summed_contribs_for_net.source_id.unique()))\n",
    "print(len(summed_contribs_for_net.sink_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "# print(set(result_df_2008['contributor.name']) - set(summed_contribs_for_net['contributor.name']))# peart, dennis\n",
    "print(len(set(result_df_2008['contributor_ids']))) #set(summed_contribs_for_net['bonica.cid'])# peart, dennis\n",
    "\n",
    "# result_df_2008.loc['contributor_ids', 'Contributor_ID'].unique()\n",
    "\n",
    "cid_mapping.value_counts()\n",
    "\n",
    "# cid_counts = pd.DataFrame(result_df_2008.groupby('contributor_ids').agg({'Contributor_ID':'count'}))\n",
    "# cid_counts\n",
    "# set([1,2,3,4]) - set([3,4,5,6])\n",
    "# print(set(result_df_2008['contributor.name']))\n",
    "# print(set(summed_contribs_for_net['contributor.name']))\n",
    "\n",
    "# print(set(result_df_2008['contributor.name']) - set(summed_contribs_for_net['contributor.name']))# peart, dennis\n",
    "\n",
    "\n",
    "# display(summed_contribs_for_net[summed_contribs_for_net['contributor.name'] == 'peart, dennis'])\n",
    "# display(result_df_2008[result_df_2008['contributor.name'] == 'peart, dennis'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result_df_2008.shape)\n",
    "print(contrib_for_net.shape)\n",
    "print(summed_contribs_for_net.shape)\n",
    "\n",
    "# display(result_df_2008[result_df_2008['Recipient_ID'].isna() | result_df_2008['Contributor_ID'].isna()].shape)\n",
    "display(contrib_for_net[contrib_for_net['source_id'].isna() | contrib_for_net['sink_id'].isna()].shape)\n",
    "display(summed_contribs_for_net[summed_contribs_for_net['source_id'].isna() | summed_contribs_for_net['sink_id'].isna()].shape)\n",
    "\n",
    "# display(result_df_2008[result_df_2008['Recipient_ID'].isna() | result_df_2008['Contributor_ID'].isna()])\n",
    "display(contrib_for_net[contrib_for_net['source_id'].isna() | contrib_for_net['sink_id'].isna()])\n",
    "display(summed_contribs_for_net[summed_contribs_for_net['source_id'].isna() | summed_contribs_for_net['sink_id'].isna()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
